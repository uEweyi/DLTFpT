{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkIRIR7XxpP0"
      },
      "source": [
        "# Deep Neural Network in PyTorch\n",
        "\n",
        "In this notebook, we adapt our [TensorFlow Deep Net](https://github.com/jonkrohn/DLTFpT/blob/master/notebooks/deep_net_in_tensorflow.ipynb) to PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJv0N43uyVsy"
      },
      "source": [
        "#### Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rAh1QLwWyYvY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-Nh_zNUyarq"
      },
      "source": [
        "#### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6vBWZlFGydPY",
        "outputId": "eb46fb85-08fc-4185-c8ee-a1a600838c10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 34442526.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 70020632.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 20657154.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3007186.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train = MNIST('data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test = MNIST('data', train=False, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi5GT2I_yobV"
      },
      "source": [
        "#### Batch data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wbqPKnEXy9i6"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train, batch_size=128) \n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=128) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgJkRG_hzM1r"
      },
      "source": [
        "#### Design neural network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7TnSFYGpzRMD"
      },
      "outputs": [],
      "source": [
        "n_input = 784\n",
        "n_dense_1 = 64\n",
        "n_dense_2 = 64\n",
        "n_dense_3 = 64\n",
        "n_out = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YAFJBtBYzYcc"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    \n",
        "    # first hidden layer: \n",
        "    nn.Linear(n_input, n_dense_1), \n",
        "    nn.ReLU(), \n",
        "    nn.BatchNorm1d(n_dense_1),\n",
        "    \n",
        "    # second hidden layer: \n",
        "    nn.Linear(n_dense_1, n_dense_2), \n",
        "    nn.ReLU(), \n",
        "    nn.BatchNorm1d(n_dense_2),\n",
        "    \n",
        "    # third hidden layer: \n",
        "    nn.Linear(n_dense_2, n_dense_3), \n",
        "    nn.ReLU(), \n",
        "    nn.BatchNorm1d(n_dense_3),\n",
        "    nn.Dropout(),  \n",
        "    \n",
        "    # output layer: \n",
        "    nn.Linear(n_dense_3, n_out) \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjfVGdDp0YDJ",
        "outputId": "fc5f0c9d-c51d-4d43-9fa2-35fc5c46240e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                   [-1, 64]          50,240\n",
            "              ReLU-2                   [-1, 64]               0\n",
            "       BatchNorm1d-3                   [-1, 64]             128\n",
            "            Linear-4                   [-1, 64]           4,160\n",
            "              ReLU-5                   [-1, 64]               0\n",
            "       BatchNorm1d-6                   [-1, 64]             128\n",
            "            Linear-7                   [-1, 64]           4,160\n",
            "              ReLU-8                   [-1, 64]               0\n",
            "       BatchNorm1d-9                   [-1, 64]             128\n",
            "          Dropout-10                   [-1, 64]               0\n",
            "           Linear-11                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 59,594\n",
            "Trainable params: 59,594\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.23\n",
            "Estimated Total Size (MB): 0.24\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(model, input_size=(n_input,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzT_k2fF0gT1"
      },
      "source": [
        "#### Configure training hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VS9m8bPd0j-T"
      },
      "outputs": [],
      "source": [
        "cost_fxn = nn.CrossEntropyLoss() # includes softmax activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9AKQugeh0lhM"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVVGdPLI0oLk"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OxZMGQHd0s_b"
      },
      "outputs": [],
      "source": [
        "def accuracy_pct(pred_y, true_y):\n",
        "  _, prediction = torch.max(pred_y, 1) # returns maximum values, indices; fed tensor, dim to reduce\n",
        "  correct = (prediction == true_y).sum().item()\n",
        "  return (correct / true_y.shape[0]) * 100.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "481O1w790pvJ",
        "outputId": "47fdadcf-2c78-4af6-9886-878e30fc6fd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "469"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "n_batches = len(train_loader)\n",
        "n_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K-f-uJb0x7A",
        "outputId": "d4bff0aa-fb79-4d31-d5c8-5874a01546ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10 epochs. \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 1/10 complete. Cost: 0.407, Accuracy: 88.9% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 2/10 complete. Cost: 0.159, Accuracy: 95.5% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 3/10 complete. Cost: 0.116, Accuracy: 96.7% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 4/10 complete. Cost: 0.092, Accuracy: 97.4% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 5/10 complete. Cost: 0.077, Accuracy: 97.7% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 6/10 complete. Cost: 0.066, Accuracy: 98.1% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 7/10 complete. Cost: 0.057, Accuracy: 98.3% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 8/10 complete. Cost: 0.052, Accuracy: 98.4% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 9/10 complete. Cost: 0.046, Accuracy: 98.6% \n",
            "\n",
            "Step 100\n",
            "Step 200\n",
            "Step 300\n",
            "Step 400\n",
            "Epoch 10/10 complete. Cost: 0.039, Accuracy: 98.8% \n",
            "\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 10 \n",
        "\n",
        "print('Training for {} epochs. \\n'.format(n_epochs))\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  \n",
        "  avg_cost = 0.0\n",
        "  avg_accuracy = 0.0\n",
        "  \n",
        "  for i, (X, y) in enumerate(train_loader): # enumerate() provides count of iterations  \n",
        "    \n",
        "    # forward propagation:\n",
        "    X_flat = X.view(X.shape[0], -1)\n",
        "    y_hat = model(X_flat)\n",
        "    cost = cost_fxn(y_hat, y)\n",
        "    avg_cost += cost / n_batches\n",
        "    \n",
        "    # backprop and optimization via gradient descent: \n",
        "    optimizer.zero_grad() # set gradients to zero; .backward() accumulates them in buffers\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # calculate accuracy metric:\n",
        "    accuracy = accuracy_pct(y_hat, y)\n",
        "    avg_accuracy += accuracy / n_batches\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "      print('Step {}'.format(i + 1))\n",
        "    \n",
        "  print('Epoch {}/{} complete. Cost: {:.3f}, Accuracy: {:.1f}% \\n'\n",
        "        .format(epoch + 1, n_epochs, avg_cost, avg_accuracy)) \n",
        "\n",
        "print('Training complete.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKqQEbxY0ris"
      },
      "source": [
        "#### Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5RxXcEy04UM",
        "outputId": "55f50500-8777-434f-9687-2a784fe69a93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "n_test_batches = len(test_loader)\n",
        "n_test_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqeluNIm06pT",
        "outputId": "5e505bdd-8c5b-4e85-fd7e-5a7b1189962b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test cost: 0.099, Test accuracy: 97.5%\n"
          ]
        }
      ],
      "source": [
        "model.eval() # disables dropout and batch norm\n",
        "\n",
        "with torch.no_grad(): # disables autograd, reducing memory consumption\n",
        "  \n",
        "  avg_test_cost = 0.0\n",
        "  avg_test_acc = 0.0\n",
        "  \n",
        "  for X, y in test_loader:\n",
        "    \n",
        "    # make predictions: \n",
        "    X_flat = X.view(X.shape[0], -1)\n",
        "    y_hat = model(X_flat)\n",
        "    \n",
        "    # calculate cost: \n",
        "    cost = cost_fxn(y_hat, y)\n",
        "    avg_test_cost += cost / n_test_batches\n",
        "    \n",
        "    # calculate accuracy:\n",
        "    test_accuracy = accuracy_pct(y_hat, y)\n",
        "    avg_test_acc += test_accuracy / n_test_batches\n",
        "\n",
        "print('Test cost: {:.3f}, Test accuracy: {:.1f}%'.format(avg_test_cost, avg_test_acc))\n",
        "\n",
        "# model.train() # 'undoes' model.eval()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "deep_net_in_pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}